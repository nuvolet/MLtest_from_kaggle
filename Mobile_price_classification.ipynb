{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53896684-49de-4c5a-a49f-f2239b026c61",
   "metadata": {},
   "source": [
    "Mobile Price Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af5bdc1-717a-44c8-83f5-53f5fbfbe299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:WARNING: The JSON-LD `@context` is not standard. Refer to the official @context (e.g., from the example datasets in https://github.com/mlcommons/croissant/tree/main/datasets/1.0). The different keys are: {'samplingRate', 'rai', 'isLiveDataset', 'examples'}\n",
      "WARNING:absl:Found the following 1 warning(s) during the validation:\n",
      "  -  [Metadata(IMDB Movies Dataset)] Property \"http://mlcommons.org/croissant/citeAs\" is recommended, but does not exist.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RecordSet(uuid=\"imdb_top_1000.csv\")]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.kaggle.com/api/v1/datasets/download/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows?datasetVersionNumber=1...: 100%|â–ˆ| 175k/175k [00:00<00:00\n"
     ]
    },
    {
     "ename": "GenerationError",
     "evalue": "An error occured during the streaming generation of the dataset, more specifically during the operation Read(imdb_top_1000.csv_fileobject)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/ml-env/lib/python3.11/site-packages/mlcroissant/_src/operation_graph/execute.py:115\u001b[39m, in \u001b[36mexecute_operations_in_streaming\u001b[39m\u001b[34m(record_set, operations, list_of_operations, result)\u001b[39m\n\u001b[32m    108\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m execute_operations_in_streaming(\n\u001b[32m    109\u001b[39m             record_set=record_set,\n\u001b[32m    110\u001b[39m             operations=operations,\n\u001b[32m    111\u001b[39m             list_of_operations=list_of_operations[i + \u001b[32m1\u001b[39m :],\n\u001b[32m    112\u001b[39m             result=operation.call(file),\n\u001b[32m    113\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m read_all_files()\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/ml-env/lib/python3.11/site-packages/mlcroissant/_src/operation_graph/execute.py:112\u001b[39m, in \u001b[36mexecute_operations_in_streaming.<locals>.read_all_files\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    107\u001b[39m logging.info(\u001b[33m\"\u001b[39m\u001b[33mExecuting \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, operation)\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m execute_operations_in_streaming(\n\u001b[32m    109\u001b[39m     record_set=record_set,\n\u001b[32m    110\u001b[39m     operations=operations,\n\u001b[32m    111\u001b[39m     list_of_operations=list_of_operations[i + \u001b[32m1\u001b[39m :],\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     result=operation.call(file),\n\u001b[32m    113\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/ml-env/lib/python3.11/site-packages/mlcroissant/_src/operation_graph/operations/read.py:228\u001b[39m, in \u001b[36mRead.call\u001b[39m\u001b[34m(self, files)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.node.encoding_formats, \u001b[33m\"\u001b[39m\u001b[33mEncoding format is not specified.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m file_content = \u001b[38;5;28mself\u001b[39m._read_file_content(\u001b[38;5;28mself\u001b[39m.node.encoding_formats, file)\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _should_append_line_numbers(\u001b[38;5;28mself\u001b[39m.fields):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/ml-env/lib/python3.11/site-packages/mlcroissant/_src/operation_graph/operations/read.py:194\u001b[39m, in \u001b[36mRead._read_file_content\u001b[39m\u001b[34m(self, encoding_formats, file)\u001b[39m\n\u001b[32m    191\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame({\n\u001b[32m    192\u001b[39m             FileProperty.content: [out],\n\u001b[32m    193\u001b[39m         })\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    195\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of the provided encoding formats: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencoding_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for file\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m returned a valid pandas dataframe.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    197\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: None of the provided encoding formats: application/vnd.ms-excel for file /Users/rainbowfarm/.cache/croissant/extract/96dd09ceaa15a6e6906a98a900a80249faa5bdbf7730aa2c07c64e0700677337/imdb_top_1000.csv returned a valid pandas dataframe.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mGenerationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(record_sets)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Fetch the records and put them in a DataFrame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m record_set_df = pd.DataFrame(croissant_dataset.records(record_set=record_sets[\u001b[32m0\u001b[39m].uuid))\n\u001b[32m     13\u001b[39m record_set_df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/ml-env/lib/python3.11/site-packages/pandas/core/frame.py:843\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    841\u001b[39m         data = np.asarray(data)\n\u001b[32m    842\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m         data = \u001b[38;5;28mlist\u001b[39m(data)\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) > \u001b[32m0\u001b[39m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_dataclass(data[\u001b[32m0\u001b[39m]):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/ml-env/lib/python3.11/site-packages/mlcroissant/_src/datasets.py:166\u001b[39m, in \u001b[36mRecords.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;66;03m# We can stream the dataset iff the operation graph is a path graph (meaning\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# that all operations lie on a single straight line, i.e. have an\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[38;5;66;03m# in-degree of 0 or 1. That means that the operation graph is a single line\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# (without external joins for example).\u001b[39;00m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_streamable_dataset(operations):\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m execute_operations_in_streaming(\n\u001b[32m    167\u001b[39m         record_set=\u001b[38;5;28mself\u001b[39m.record_set,\n\u001b[32m    168\u001b[39m         operations=operations,\n\u001b[32m    169\u001b[39m     )\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m execute_operations_sequentially(\n\u001b[32m    172\u001b[39m         record_set=\u001b[38;5;28mself\u001b[39m.record_set, operations=operations\n\u001b[32m    173\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/ml-env/lib/python3.11/site-packages/mlcroissant/_src/operation_graph/execute.py:121\u001b[39m, in \u001b[36mexecute_operations_in_streaming\u001b[39m\u001b[34m(record_set, operations, list_of_operations, result)\u001b[39m\n\u001b[32m    119\u001b[39m         result = operation.call(result)\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m GenerationError(\n\u001b[32m    122\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAn error occured during the streaming generation of the dataset, more\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m specifically during the operation \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moperation\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mGenerationError\u001b[39m: An error occured during the streaming generation of the dataset, more specifically during the operation Read(imdb_top_1000.csv_fileobject)"
     ]
    }
   ],
   "source": [
    "import mlcroissant as mlc\n",
    "import pandas as pd\n",
    "\n",
    "# Fetch the Croissant JSON-LD\n",
    "croissant_dataset = mlc.Dataset('https://www.kaggle.com/datasets/harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows/croissant/download')\n",
    "\n",
    "# Check what record sets are in the dataset\n",
    "record_sets = croissant_dataset.metadata.record_sets\n",
    "print(record_sets)\n",
    "\n",
    "# Fetch the records and put them in a DataFrame\n",
    "record_set_df = pd.DataFrame(croissant_dataset.records(record_set=record_sets[0].uuid))\n",
    "record_set_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1206d8f2-4d20-48ba-8cb2-9f64a1d69e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
